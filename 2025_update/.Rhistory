library(tidyverse)
library(openxlsx)
library(magrittr)
value_url <- "https://redfin-public-data.s3.us-west-2.amazonaws.com/redfin_market_tracker/redfin_metro_market_tracker.tsv000.gz"
save_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/metric14_median_home_price_by_type/metric14_raw.csv"
metro_area <- "Seattle, WA"
earliestdate <- "2012-07-01"
latestdate <- "2025-03-01"
# Import Redfin data, limit to metro area and by date
redfin_raw <- read_tsv(value_url)
# Limited to Metro area selected above
value <- redfin_raw %>%
filter(str_detect(region, metro_area)) %>%
transmute(
date = period_begin,
region = region,
property_type = property_type,
median_sale_price = median_sale_price)
# limit to all residential properties, restrict to date range selected above
value <- value %>%
filter(!(property_type == "Multi-Family (2-4 Unit)"))
value <- with(value, value[(date >= earliestdate & date <= latestdate), ])
value$month <- str_sub(value$date, 1, 7)
# Sort by date and property type/pivot
value <- value[order(as.Date(value$date),(factor(value$property_type, levels = c("Condo/Co-op","Single Family Residential","Townhouse","All Residential")))),]
value <- value %>%
pivot_wider(names_from = property_type, values_from = median_sale_price)
# Filter to month of latest date
value <- subset(value, str_sub(value$month, -2,-1) == str_sub(latestdate, -5,-4))
View(value)
View(redfin_raw)
latestdate <- "2025-02-01"
# Import Redfin data, limit to metro area and by date
redfin_raw <- read_tsv(value_url)
# Limited to Metro area selected above
value <- redfin_raw %>%
filter(str_detect(region, metro_area)) %>%
transmute(
date = period_begin,
region = region,
property_type = property_type,
median_sale_price = median_sale_price)
# limit to all residential properties, restrict to date range selected above
value <- value %>%
filter(!(property_type == "Multi-Family (2-4 Unit)"))
value <- with(value, value[(date >= earliestdate & date <= latestdate), ])
value$month <- str_sub(value$date, 1, 7)
# Sort by date and property type/pivot
value <- value[order(as.Date(value$date),(factor(value$property_type, levels = c("Condo/Co-op","Single Family Residential","Townhouse","All Residential")))),]
value <- value %>%
pivot_wider(names_from = property_type, values_from = median_sale_price)
# Filter to month of latest date
value <- subset(value, str_sub(value$month, -2,-1) == str_sub(latestdate, -5,-4))
View(value)
# Export
write.csv(value,file = save_path)
View(value)
library(openxlsx)
library(tidyr)
library(tidyverse)
save_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/metric16_17_affordability_indexes/metric16_17_raw.csv"
mb_hai_raw <- "https://public.tableau.com/app/profile/mason.virant/viz/County_DB_HAIMedianBuyer_Q4_2024/DB-HAIMedianBuyer.csv?County=King,Kitsap,Pierce,Snohomish"
ftb_hai_raw <- "https://public.tableau.com/app/profile/mason.virant/viz/County_DB_HAIFirstTimeBuyer_Q4_2024/DB-HAIFirstTimeBuyer.csv?County=King,Kitsap,Pierce,Snohomish"
# --------------- Download Data ---------------
mb_hai_raw <- read_csv(mb_hai_raw)
library(readr)
# --------------- Download Data ---------------
mb_hai_raw <- read_csv(mb_hai_raw)
library(openxlsx)
library(tidyr)
library(tidyverse)
library(readr)
save_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/metric16_17_affordability_indexes/metric16_17_raw.csv"
mb_hai_link <- "https://public.tableau.com/app/profile/mason.virant/viz/County_DB_HAIMedianBuyer_Q4_2024/DB-HAIMedianBuyer.csv?County=King,Kitsap,Pierce,Snohomish"
ftb_hai_link <- "https://public.tableau.com/app/profile/mason.virant/viz/County_DB_HAIFirstTimeBuyer_Q4_2024/DB-HAIFirstTimeBuyer.csv?County=King,Kitsap,Pierce,Snohomish"
# --------------- Download Data ---------------
mb_hai_raw <- read_csv(mb_hai_link)
library(openxlsx)
library(tidyr)
library(tidyverse)
library(readr)
dir.create("J:/Projects/V2050/Housing/Monitoring/2025Update/data/raw", recursive = TRUE, showWarnings = FALSE)
# Define download destination
mb_hai_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/raw/DB-HAIMedianBuyer.csv"
ftb_hai_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/raw/DB-HAIFirstTimeBuyer.csv"
# Define Tableau dashboard URLs (not direct CSV links, but ones that trigger download)
mb_hai_link <- "https://public.tableau.com/app/profile/mason.virant/viz/County_DB_HAIMedianBuyer_Q4_2024/DB-HAIMedianBuyer.csv?County=King,Kitsap,Pierce,Snohomish"
ftb_hai_link <- "https://public.tableau.com/app/profile/mason.virant/viz/County_DB_HAIFirstTimeBuyer_Q4_2024/DB-HAIFirstTimeBuyer.csv?County=King,Kitsap,Pierce,Snohomish"
# Define download destination
mb_hai_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/raw/DB-HAIMedianBuyer.csv"
ftb_hai_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/raw/DB-HAIFirstTimeBuyer.csv"
# Define Tableau dashboard URLs (not direct CSV links, but ones that trigger download)
mb_hai_link <- "https://public.tableau.com/app/profile/mason.virant/viz/County_DB_HAIMedianBuyer_Q4_2024/DB-HAIMedianBuyer.csv?County=King,Kitsap,Pierce,Snohomish"
ftb_hai_link <- "https://public.tableau.com/app/profile/mason.virant/viz/County_DB_HAIFirstTimeBuyer_Q4_2024/DB-HAIFirstTimeBuyer.csv?County=King,Kitsap,Pierce,Snohomish"
# Download the files
download.file(mb_hai_link, mb_hai_path, mode = "wb")
dir.create("J:/Projects/V2050/Housing/Monitoring/2025Update/data/raw/metric16_17_affordability_indexes", recursive = TRUE, showWarnings = FALSE)
mb_hai_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/metric16_17_affordability_indexes/raw/DB-HAIMedianBuyer.csv"
ftb_hai_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/metric16_17_affordability_indexes/raw/DB-HAIFirstTimeBuyer.csv"
# Define Tableau dashboard URLs (not direct CSV links, but ones that trigger download)
mb_hai_link <- "https://public.tableau.com/app/profile/mason.virant/viz/County_DB_HAIMedianBuyer_Q4_2024/DB-HAIMedianBuyer.csv?County=King,Kitsap,Pierce,Snohomish"
ftb_hai_link <- "https://public.tableau.com/app/profile/mason.virant/viz/County_DB_HAIFirstTimeBuyer_Q4_2024/DB-HAIFirstTimeBuyer.csv?County=King,Kitsap,Pierce,Snohomish"
# --------------- Download Data ---------------
# Download the files
download.file(mb_hai_link, mb_hai_path, mode = "wb")
install.packages("RSelenium")
install.packages("wdman")     # Manages browser drivers
install.packages("binman")    # Manages binary files
install.packages("netstat")   # Required by RSelenium
library(openxlsx)
library(tidyr)
library(tidyverse)
library(readr)
library(RSelenium)
# Set up Chrome Browser
download_dir <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/metric16_17_affordability_indexes/raw"
eCaps <- list(
chromeOptions = list(
prefs = list(
"download.default_directory" = normalizePath(download_dir),
"download.prompt_for_download" = FALSE,
"directory_upgrade" = TRUE,
"safebrowsing.enabled" = TRUE
),
args = list('--headless', '--disable-gpu')  # Run Chrome in headless mode
)
)
rD <- rsDriver(browser = "chrome", chromever = "latest", extraCapabilities = eCaps, verbose = FALSE, port = 4545L)
library(dplyr)
library(stringr)
library(readr)
library(tidyr)
data_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/metric15_median_home_price_by_county/data_redfin.csv"
save_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/metric15_median_home_price_by_county/metric15_raw.csv"
month <- "June"
# Pull in data downloaded from tableau dashboard (make sure all 4 counties are visible before exporting to CSV)
county_raw <- read_tsv(file = data_path, locale = locale(encoding = "UTF-16LE"))
# Clean
colnames(county_raw) <- as.character(county_raw[1, ])
county_raw <- county_raw[-1, ]
county <- county_raw %>%
select(1, starts_with(month)) %>%
mutate(across(
.cols = -1,                               # Apply to all columns except the first (region)
.fns = ~ as.numeric(
str_replace_all(.x, "\\$", "") |>       # Remove $
str_replace_all("K", "000")           # Replace K with 000
)))
View(county)
ZHVI_raw = read.csv(ZHVI_url)
library(openxlsx)
library(tidyr)
library(stringr)
library(dplyr)
library(magrittr)
library(psrccensus)
library(tidycensus)
library(purrr)
library(readxl)
library(psrchousing)
# assumptions
#  ZHVI: Zillow Home Value Index - All Homes (SFR & Condo) Time series, Smoothed, Seasonally-Adjusted
#  ZORI: Zillow Observed Rent Index - All Homes + Multifamily, Smoothed, Seasonally-Adjusted
export_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/data/metric12-13_metro_area_rent_home_value"
ZHVI_url <- "https://files.zillowstatic.com/research/public_csvs/zhvi/Metro_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv"
ZORI_url <- "https://files.zillowstatic.com/research/public_csvs/zori/Metro_zori_uc_sfrcondomfr_sm_sa_month.csv?t=1711667054"
ZHVI_raw = read.csv(ZHVI_url)
ZORI_raw = read.csv(ZORI_url)
# Clean Zillow data
ZHVI <- subset(ZHVI_raw, ZHVI_raw$RegionName == 'Seattle, WA')
ZORI <- subset(ZORI_raw, ZORI_raw$RegionName == 'Seattle, WA')
ZHVI$source <- "ZHVI"
ZORI$source <- "ZORI"
common <- intersect(colnames(ZHVI), colnames(ZORI))
all_data <- rbind(ZHVI[common], ZORI[common])
all_data %<>%
relocate(source, .before = RegionID)
colnames(all_data)<-gsub("X","",colnames(all_data))
View(all_data)
View(ZORI_raw)
library(dplyr)
library(openxlsx)
library(tidyverse)
library(psrchousing)
export_path <- "J:/Projects/V2050/Housing/Monitoring/2025Update/Data/metric01_pop_growth_hu_supply"
source_info <- c("OFM April 1 Population and Housing Estimates. Data representing 1980, 1990, 2000, 2010, 2020, 2025. Calculated by Eric Clute.")
years <- c(1980, 1990, 2000, 2010, 2020, 2025)
# Import ---------------------
hu_raw <- ofm_county_housing_unit_data()
pop_raw <- ofm_county_population_data()
# Clean up data, join ---------------------
hu <- hu_raw %>% filter(geography == "Region") %>% select(year, total) %>% rename(units = total)
pop <- pop_raw %>% filter(geography == "Region") %>% ungroup() %>% select(year, population)
analysis <- left_join(hu,pop, by = "year")
# Calculate change in pop, hu, and ratio ---------------------
analysis <- analysis %>%
filter(year %in% years) %>%
mutate(hu_change = units - lag(units),
pop_change = population - lag(population),
hu_pop_ratio = pop_change / hu_change,
hu_per_cap_1k = hu_change / population * 1000)
View(analysis)
export_file <- paste0(export_path, "/metric01_raw.xlsx")
work_book <- createWorkbook()
addWorksheet(work_book, sheetName = "analysis")
writeData(work_book, sheet = "analysis", analysis)
writeData(work_book, sheet = "analysis", x = data.frame(source_info), startRow = nrow(analysis) + 3, startCol = 1)
saveWorkbook(work_book, file = export_file, overwrite = TRUE)
